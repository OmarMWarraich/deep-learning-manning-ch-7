{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Deep Learning Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1.1 Introduction to the functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, layers\n",
    "input_tensor = Input (shape=(32,))     # A tensor\n",
    "dense = layers.Dense(32, activation = 'relu')   # A layer is a function\n",
    "output_tensor = dense(input_tensor)         # A layer may be called a tensor and it returns a tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimal Eg., Sequential Model with its eq in functional API side by side:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "seq_model = Sequential()       # Seq Md\n",
    "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
    "seq_model.add(layers.Dense(32, activation='relu'))\n",
    "seq_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "input_tensor = Input(shape=(64,))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)    # Func eq\n",
    "\n",
    "model = Model(input_tensor, output_tensor)   # The Model class turns an input tensor and output tensor in2 a model\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The APi is same as that of sequntial when it comes to compiling training or evaluating such an instance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')  # Compiles the model\n",
    "\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000, 64))\n",
    "y_train = np.random.random((1000, 10))         # Gen dummy numpy data to train on\n",
    "\n",
    "model.fit(x_train, y_train,epochs=10, batch_size=128)     # Trains the model for 10 epochs\n",
    "score = model.evaluate(x_train, y_train)       # evaluates the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-input models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functional API helps build models having multiple inputs. Use Keras merge operation such as keras.layers.add, keras.layers.concatenate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Functional API implwemetation of a two-point question-answering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "text_input = Input(shape=(None,), dtype = 'int32', name = 'text')     #The text input is a variable-length sequence\n",
    "                                                                     #of integers. Note: U can optionally name the inputs.\n",
    "embedded_text = layers.Embedding(         # Embeds the inputs into a sequence of vectors of size 64.                \n",
    "    64, text_vocabulary_size)(text_input)    \n",
    "\n",
    "encoded_text = layers.LSTM(32)(embedded_text)  #Encodes the vectors in a single vector via an LSTM.\n",
    "\n",
    "question_input = Input(shape=(None,),     # Same process (with different layer instances) for the question.\n",
    "                              dtype='int32',\n",
    "                              name='question')\n",
    "\n",
    "embedded_question = layers.Embedding(32,  question_vocabulary_size)(question_input)\n",
    "\n",
    "encoded_question= layers.LSTM(16)(embedded_question)   \n",
    "\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question], axis = -1) #Concatenation\n",
    "\n",
    "answer = layers.Dense(answer_vocabulary_size, activation='softmax')(concatenated) # Adds a softmax classifier on top.\n",
    "\n",
    "model = Model([text_input, question_input], answer) # Specify the two inputs and outputs at model instantiation.\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "                         loss='categorical_crossentropy',\n",
    "                         metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 7.2  Feeding Data to a multi-input model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1000\n",
    "max_length = 100\n",
    "\n",
    "text = np.random.randint(1, text_vocabulary_size,\n",
    "                         size=(num_samples, max_length))      # Generates dummy Numpy data\n",
    "\n",
    "question = np.random.randint(1, question_vocabulary_size,\n",
    "                         size=(num_samples, max_length))\n",
    "\n",
    "answers = np.random.randint(0, 1, \n",
    "                         size=(num_samples, answer_vocabulary_size))  # Answers are 1hot encoded, not integers.\n",
    "\n",
    "model.fit([text, question], answers, epochs=10, batch_size=128)  # Fitting using a list of inputs.\n",
    "\n",
    "model.fit({'text': text, 'question': question}, answers,\n",
    "          epochs=10, batch_size=128)    # Fitting using a dictionary of inputs(only if inputs are named)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.3 Multi-output models: Functional API also builds models with multiple(outputs)(heads). e.g., a network attempting\n",
    "                           to simultaneously predict different props of the data such as social media posts predicting \n",
    "                           attributes of a person such as age, gender and income level.                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 7.3: Functional API implementation of a three output model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "vocabulary_size = 50000\n",
    "num_income_groups = 10\n",
    "\n",
    "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "embedded_posts = layers.Embedding(256, vocabulary_size)(posts_input)\n",
    "x = layers.Conv1D(128, 5, activation='relu')(embedded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "age_prediction = layers.Dense(1, name='age')(x)\n",
    "income_prediction = layers.Dense(num_income_groups, activation='softmax', name='income')(x)\n",
    "gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\n",
    "\n",
    "model = Model(posts_input, [age_prediction, income_prediction, gender_prediction])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 7.4: Compilation options of a multi-output model: multiple losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "                 loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'])\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'age': 'mse',\n",
    "                    'income': 'categorical_crossentropy',\n",
    "                    'gender': 'binary_crossentropy'}) # Equivalent possible only if you give names to the output layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 7.5: Compilation options of a multi-output model: loss weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "                 loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'],\n",
    "              loss_weights=[0.25, 1., 10.])\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'age': 'mse',\n",
    "                    'income': 'categorical_crossentropy',\n",
    "                    'gender': 'binary_crossentropy'}, # Equivalent possible only if you give names to the output layers\n",
    "              loss_weights={'age': 0.25,\n",
    "                            'income': 1.,\n",
    "                            'gender': 10.})      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing 7.6: Feeding data to a multi-output model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(posts, [age_targerts, income_targets, gender_targets],\n",
    "          epochs=10, batch_size=64)\n",
    "#age_targets, income_targets and gender_targets are assumed to be numpy arrays\n",
    "modelfit(posts, { 'age': age_targets,\n",
    "                  'income': income_targets,\n",
    "                  'gender': gender_targets},\n",
    "         epochs=10, batch_size=64)   # Equivalent(possible only if you give name to the output layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1.4: Directed acyclic graphs of layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural networks in Keras are also allowed to be arbitrary directed acyclic graphs of layers.\n",
    "# These graphs dont have cycles.\n",
    "# Its impossible for a tensor x to become the input of one of the layers that generated x\n",
    "# The only processing loops that are allowed(i.e., recurrent connections) are those internal to recurrent layers\n",
    "# Several common nn components are implemented as graph. Notable (1) Inception Modules, (2) Residual connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXAMPLE: MODEL IMPLEMENTATION OF INCEPTION MODULE EXAMPLE USING THE FUNCTIONAL API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "branch_a = layers.Conv2D(128, 1,\n",
    "                         activation='relu', strides=2)(x)\n",
    "#Above:Every branch has the same stride value (2),\n",
    "#which is necessary to keep all branch outputs\n",
    "#the same size so you can concatenate them\n",
    "branch_b = layers.Conv2D(128, 1,\n",
    "                         activation='relu')(x)\n",
    "branch_b = layers.Conv2D(128, 3,\n",
    "                         activation='relu', strides=2)(branch_b) # In this branch, striding occurs in the spatial convolution layer.\n",
    "branch_c = layers.AveragePooling2D(3, strides=2)(x)\n",
    "branch_c = layers.Conv2D(128, 3, activation='relu')(branch_c)  # In this branch, striding occurs in the average pooling layer.\n",
    "branch_d = layers.Conv2D(128, 1,\n",
    "                         activation='relu')(x)\n",
    "branch_a = layers.Conv2D(128, 3,\n",
    "                         activation='relu')(branch_d)\n",
    "output = layers.concatenate(\n",
    "    [branch_a, branch_b, branch_c, branch_d], axis=-1)  # Concatenates the branch outputs to obtain the module output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: The full Inception V3 architecture is available in Keras as keras.applications.inception_v3.InceptionV3, including weights pretrained on the ImageNet dataset. 'Xception', another model. literally stands for extreme inception, inspired by Inception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESIDUAL CONNECTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A residual connection consists of making the output of an earlier layer available as input to a later layer, effectivelycreating a shortcut in a sequential network. Example below assuming the existence of a 4D input tensor x:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "x = ...\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)  # Applies a transformation to x\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "\n",
    "y = layers.add([y, x])     # Adds the original x back to the output features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the following imp a residual connection when the feature-map sizes differ, using a linear residual connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "x = ...\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.MaxPooling2D(2, strides=2)(y)\n",
    "\n",
    "residual = layers.Conv2D(128, 1, strides=2, padding='same')(x)  # Uses a 1 x 1 convolution to linearly downsample the \n",
    "                                                                # original x tensor to the same shape as y.\n",
    "\n",
    "y = layers.add([y, residual])    # Adds the residual tensor back to the output features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representational bottlenecks in deep learning\n",
    "Residual connections, by reinjecting earlier information downstream, help to mitigate line losses. when in sequential\n",
    "models each successive representation layer is built on top of activated layer, with small layers, the models might\n",
    "be constrained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vanishing gradients\n",
    "Just like the LSTM layer in feedback recurrent networks introduces a carry tract that propagates information parallel to the\n",
    "main processing track, Residual connections in feedforward deep networks introduce a purely linear information carry\n",
    "track parallel to the main layer stack, this helping to propagate gradients through arbitrary deep stack of layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.5 Layer weight sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Imp Feature of Functional API: ability to reuse a layer instance several times, calling layer instance twice, same \n",
    "                               weights are used with every call and no new layer for each call is instantiated.\n",
    "                               Several branches share the same representations and learn these reps 4 diff input sets.\n",
    "                               e.g., 0 and 1 output score by model with inputs two sentences (assess semantic similarity btw)\n",
    "    \n",
    "    Instead of learning two independent models for processing each input sentence, both sentences shall be processed\n",
    "    with a single LSTM layer. The reps(weights) of this LSTM layer are learned based on both inputs simultaneously.\n",
    "    This is what is called a Siamese LSTM model or shared LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Siamese LSTM model implementation using layer sharing in the Keras functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "lstm = layers.LSTM(32)                        # Instantiates a single LSTM layer once\n",
    "\n",
    "left_input = Input(shape=(None, 128))  # Building left branch of the model: inputs are variable-length sequences of \n",
    "                                       # vectors of size 128 \n",
    "left_output = lstm(left_input)\n",
    "\n",
    "right_input = Input(shape=(None, 128))\n",
    "\n",
    "right_output = lstm(right_input) # Building right branch of the model: when you call an existing layer instance\n",
    "                                 # you reuse its weights\n",
    "\n",
    "merged = layers.concatenate([left_output, right_output], axis=-1)\n",
    "predictions = layers.Dense(1, activation='sigmoid')(merged)     # Builds the classifier on top\n",
    "\n",
    "model = Model([left_input, right_input], predictions)\n",
    "model.fit([left_data, right_data], targets)      # Instantiating and training the model: when you train such a model\n",
    "#,the weights of the LSTM layer are updated based on both inputs.\n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1.6: Models as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(x)    # Call a model on an input tensor and retrieve an output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1, y2 = model[x1, x2]  # When there are multiple input and output tensors, a list of tensors should be called"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights of the model are reused when the model instance is called exactly like layer instance.\n",
    "# e.g., a vision model using dual camera as its input; two parallel cameras, a few centimeters(1 inch apart).\n",
    "# Such a model can percieve depth useful in many apps. No need for two indepndent models to extract visual \n",
    "# features for the left and right b4 merging the two feeds. Such lowlevel processing can be shared across the\n",
    "# two inputs:i.e, done via layers using the same wights and thus representations. \n",
    "\n",
    "# Imp Siamese vision model(shared convolution base in keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import applications\n",
    "from keras import Input\n",
    "\n",
    "xception_base = application.Xception(weights = None, \n",
    "                                      include_top=False)  # The base image-processing model is the Xception network\n",
    "                                                                        #(convolutional base only)\n",
    "left_input = Input(shape=(250, 250, 3))\n",
    "right_input = Input(shape=(250, 250, 3))   # The inputs are 250 x 250 RGB images\n",
    "\n",
    "left_features = xception_base(left_input)\n",
    "right_input = xception_base(right_input)      # Calls the same vision model twice\n",
    "\n",
    "merged features = layers.concatenate(\n",
    "        [left_features, right_input], axis=-1)  # The merged features contain information from the right visual feed\n",
    "                                                # and the left visual feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2.1: Using Callbacks to act on a model during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop training when the validation loss is no longer improving.  Achievable through a keras callback.\n",
    "A callback is an object( a class inst imp specific meth) that is passed to the model in the call to fit and that\n",
    "is called by the model at various points during training.\n",
    "Examples of ways of using callbacks\n",
    "\n",
    "Model checkpointing- Saving the current weights of the model at different points during training.\n",
    "\n",
    "Early stopping- Interrupting training when the validation loss is no longer improving(optimization).\n",
    "\n",
    "Dynamically adjusting the value of certain params during trining-such as the learning rate of the optimizer\n",
    "\n",
    "Logging training and validation metrics during training or visualizing the reps learned by the model as dey r updated.\n",
    "\n",
    "The Keras progress bar is a callback\n",
    "\n",
    "The keras.callback includes a no. of built-in callbacks:-\n",
    "    \n",
    "    keras.callbacks.ModelCheckpoint\n",
    "    keras.callbacks.EarlyStopping\n",
    "    keras.callbacks.LearningRateScheduler\n",
    "    keras.callbacks.ReduceLROnPlateau\n",
    "    keras.callbacks.CSVLogger\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THE MODEL CHECKPOINT AND EARLYSTOPPING CALLBACKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to interrupt training as soon as overfitting starts to avoid training model for a smaller no. of epochs\n",
    "EarlyStopping callback typucally used in combo with ModelCheckpoint, continually saving the model during the training\n",
    "and hence optionally save the best model so far; the version of model achieving the best per on end of an epoch):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "callbacks_list = [ # Callbacks passed 2 model via callbacks args in fit, taking a list of call backs:any\n",
    "    keras.callbacks.EarlyStopping(    # Interrupts training when improvement stops\n",
    "        monitor = 'acc',              # Monitors the model's validation accuracy\n",
    "        patience=1,                   # Interrupts training when accuracy has stopped improving for more than one epoch i.e, 2epochs\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(  # Saves the current weights after every epoch\n",
    "        filepath='my_model.h5',       # Path to the destination model file\n",
    "        monitor='val_loss',     # These 2 args (one below) means model file wont be overwritten unless val_loss  \n",
    "        save_best_only=True,    # has improved, allowing to keep the best model during training        \n",
    "    )\n",
    "]\n",
    "\n",
    "model.compile(optimizer='rmsprop',         # Monitor accuracy to be part of the model's metrics. \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.fit(x, y,                                 # Note: Since callback monitors validation loss and validation\n",
    "          epochs=10,                            #       accuracy, validation_data needs to be passed to call to fit.     \n",
    "          batch_size=32,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THE REDUCELRONPLATEAU CALLBACK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce learning rate when validation loss stops improving. \n",
    "Reducing or increasing the learning rate in case of a loss plateau is an effective strategy to get out of local\n",
    "minima during training. Example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list - [\n",
    "    keras.callbacks.ReduceLROnPlateau(   \n",
    "        monitor='val_loss'             # monitors the model's validation loss\n",
    "        factor=0.1,                    # Divides the learning rate by 10 when trigerred\n",
    "        patience=10,                   # Callback trig after val_loss stops improving for 1-0 epochs\n",
    "    )\n",
    "]\n",
    "\n",
    "model.fit(x, y,                                 # Note: Since callback monitors validation loss and validation\n",
    "          epochs=10,                            #       accuracy, validation_data needs to be passed to call to fit.     \n",
    "          batch_size=32,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WRITING OWN CALLBACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Callbacks imp by subclassing the keras.callbacks.Callback\n",
    "Methods: any;\n",
    "    on_epoch_begin     # Called at the start of every epoch\n",
    "    on_epoch_end     # Called at the end of every epoch\n",
    "    \n",
    "    on_batch_begin     # Called right before processing each batch\n",
    "    on_batch_end     # Called right after processing each batch\n",
    "    \n",
    "    on_train_begin   # Called at the start of training\n",
    "    on_train_end   # Called at the end of training\n",
    "\n",
    "Methods called with a logs arg, a dict containing info abt the previous batch, epoch, or training run: training\n",
    "and validations metrics and so on, callback has access to following attr:-\n",
    "    self.model--The model instance from which the callback is being called\n",
    "    self.validation_data-The value of what was passed to fit as validation dat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "import numpy as np\n",
    "\n",
    "class ActivationLogger(keras.callbacks.Callback):\n",
    "    \n",
    "    def set_model(self, model):\n",
    "        self.model = model   # Kald by da parent modl b4 trnng, 2inform da callback of wat model willbe calling it\n",
    "        layer_outputs = [layer.output for layer in model.layers]\n",
    "        self.activations_model = keras.models.Model(model.input,\n",
    "                                                    layer_outputs) #Model inst returns da activations of every layer.\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.validation_data is None:\n",
    "            raise RuntimeError('Requires validation_data.')\n",
    "        validation_sample = self.validation_data[0][0:1]    # Obtains the 1st input sample of the validation data.\n",
    "        activations = self.activations_model.predict(validation_sample)\n",
    "        f = open('activations_at_epoch_' + str(epoch) + '.npz', 'w')  # Saves the array to disk(2 below)\n",
    "        np.savez(f, activations)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2.2: Introduction to TensorBoard: the TensorFlow visualization framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A browserbased visualization tool that comes packaged with TensorFlow. Only available for keras models \n",
    "TensorBoard gives access to several neat features in your browser as follows:-\n",
    "    Visualizing monitoring metrics during training\n",
    "    Visualizing your model architecture\n",
    "    Visualizing histograms of activations and gradients\n",
    "    Exploring embeddings in 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LISTING 7.7: Text xlassification model to use with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "mx_features = 2000          # No. of words to consider as features\n",
    "max_len = 500               # Cuts off text after this no. of words(among max_features most common words)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.Embedding(max_features, 128,\n",
    "                           input_length=max_len,\n",
    "                           name='embed'))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.MaxPooling1D())\n",
    "model.add(layers.Dense(1))\n",
    "model.summary()\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LISTING 7.8 Creating a directory for TensorBoard log files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir my_log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LISTING 7.9: Training the model with a TensorBoard callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir='my_log_dir',    # Log files will be written at this location\n",
    "        histogram_freq=1,        # Records activation histograms every 1 epoch        \n",
    "        embeddings_freq=1,       # Records embedding data every 1 epoch\n",
    "    )\n",
    "]\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "# Launch TensorBoard server by $ tensorboard --logdir=my_log_dir\n",
    "# Browse to http://localhost:6006 live graphs of training and vlidation metrics, Histograms tab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utility keras.utils.plot_model\n",
    "# reqs: Python pydor and pydot_ng libs as well as the graphviz library installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display shape info in graph of layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, show_shapes=True, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.3: WRAPPING UP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras callbacks provide a simple way to monitor models during training and automatically take action based on the state of model\n",
    "When you are using TensorFlow, TensorBoard is a great way to visualize model activity in yoour browser. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.1: Advance Architecture Patterns: Batch Normalization and Depthwise Separable Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BATCH NORMALIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalized_data = (data - np.mean(data, axis=...)) / np.std(data, axis=...)\n",
    "\n",
    "The main effect of batch normalization is that it helps with gradient propagation much like residual connecitons\n",
    "and thus allows for deeper networks. BatchNormalization is used liberally in many of the advanced convnet architectures\n",
    "that come packaged with Keras such as ResNet50, Inception V3, and Xception.\n",
    "\n",
    "The BatchNormalization layer is typically used after a convolution or densely connected layer.\n",
    "\n",
    "conv_model.add(layers.Conv2D(32, 3, activation='relu'))   # After a Conv layer\n",
    "conv_model.add(layers.BatchNormalization())\n",
    "\n",
    "dense_model.add(layers.Dense(32, activation='relu'))   # After a Dense layer\n",
    "dense_model.add(layers.BatchNormalization())\n",
    "\n",
    "The BatchNormalization layer takes an axis arg; specifying the feature axis 2b normalized. this arg defaults to -1,\n",
    "last axis in input tensor. This is the correct value when using Dense layers, Conv1D layers, RNN layers, and Conv2D\n",
    "layers with data_format set to \"channels_last\". Axis arg in BatchNormalization may be set to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEPTHWISE SEPARABLE CONVOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SeparableConv2D provides a drop-in replacement for Conv2D making a lighter model(fewer trainable wt params) and \n",
    "faster (fewer floating point operations ) and cause it to perform a few % pts better on its task.\n",
    "This layers performs a spatial convolution on each channel of its input, independently, b4 mixing output channels\n",
    "via a pointwise convolution(1 x 1). akin to separating the learning of spatial features and learning of \n",
    "channel-wise features.\n",
    "\n",
    "This strategy works when training small models from scratch on limited data for instance, \n",
    "a lightweight depthwise separable convnet for an image-classification task(softmax categorical classification)\n",
    "on a small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "\n",
    "height = 64\n",
    "width = 64\n",
    "channels = 3\n",
    "num_classes = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.SeparableConv2D(32, 3,\n",
    "                                 activation='relu',\n",
    "                                 input_shape=(height, width, channels, )))\n",
    "model.add(layers.SeparableConv2D(64, 3 ,activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(layers.SeparableConv2D(64, 3 ,activation='relu'))\n",
    "model.add(layers.SeparableConv2D(128, 3 ,activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(layers.SeparableConv2D(64, 3 ,activation='relu'))\n",
    "model.add(layers.SeparableConv2D(128, 3 ,activation='relu'))\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3.2 HyperParameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Process of optimizing hyperparameters:-\n",
    "    1. Choose a set of hyperparameters (automatically).\n",
    "    2. Build the corresponding model.\n",
    "    3. Fit it to your training data, and measure the final performance on the validation_data.\n",
    "    4. Choose the next set of paramters to try (automatically).\n",
    "    5. Repeat.\n",
    "    6. Eventually, measure performance on your test data.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.3: Model ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consists of pooling together the predictions of a set of different models to produce better predictions. \n",
    "Assumes that differnet good models trained independently are likely to be good for different reasons: each model\n",
    "looks at different aspects of data getting part of truth. \n",
    "The easiest way to pool the predictions of a set of classifiers( to ensemble the classifiers) is to average\n",
    "their predictions at inference time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use four different models to compute initial predictions\n",
    "preds_a = model_a.predict(x_val)\n",
    "preds_b = model_b.predict(x_val)\n",
    "preds_c = model_c.predict(x_val)\n",
    "preds_d = model_d.predict(x_val)\n",
    "\n",
    "# Below new prediction array should be more accurate than any of initial ones.\n",
    "\n",
    "final_preds = 0.25 * (preds_a + preds_b + preds_c + preds_ d)\n",
    "\n",
    "# Works if the classsifers are more or less equally good. One bad fish may spoil the final prediction to be worse than\n",
    "# best classifier of the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A smarter way to ensemble classifiers is to do a weighted average, where the weights are learned on the validation\n",
    "# data-typically, the better classifiers are given a higher weight and vice versa\n",
    "\n",
    "preds_a = model_a.predict(x_val)\n",
    "preds_b = model_b.predict(x_val)\n",
    "preds_c = model_c.predict(x_val)\n",
    "preds_d = model_d.predict(x_val)\n",
    "\n",
    "final_preds = 0.5 * preds_a + 0.25 + 0.25 * preds_b + 0.1 * preds_c + 0.15 * preds_d\n",
    "\n",
    "# Diversity is the key here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
