{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Deep Learning Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1.1 Introduction to the functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, layers\n",
    "input_tensor = Input (shape=(32,))     # A tensor\n",
    "dense = layers.Dense(32, activation = 'relu')   # A layer is a function\n",
    "output_tensor = dense(input_tensor)         # A layer may be called a tensor and it returns a tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimal Eg., Sequential Model with its eq in functional API side by side:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "seq_model = Sequential()       # Seq Md\n",
    "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
    "seq_model.add(layers.Dense(32, activation='relu'))\n",
    "seq_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "input_tensor = Input(shape=(64,))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)    # Func eq\n",
    "\n",
    "model = Model(input_tensor, output_tensor)   # The Model class turns an input tensor and output tensor in2 a model\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The APi is same as that of sequntial when it comes to compiling training or evaluating such an instance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')  # Compiles the model\n",
    "\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000, 64))\n",
    "y_train = np.random.random((1000, 10))         # Gen dummy numpy data to train on\n",
    "\n",
    "model.fit(x_train, y_train,epochs=10, batch_size=128)     # Trains the model for 10 epochs\n",
    "score = model.evaluate(x_train, y_train)       # evaluates the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-input models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functional API helps build models having multiple inputs. Use Keras merge operation such as keras.layers.add, keras.layers.concatenate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Functional API implwemetation of a two-point question-answering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "text_input = Input(shape=(None,), dtype = 'int32', name = 'text')     #The text input is a variable-length sequence\n",
    "                                                                     #of integers. Note: U can optionally name the inputs.\n",
    "embedded_text = layers.Embedding(         # Embeds the inputs into a sequence of vectors of size 64.                \n",
    "    64, text_vocabulary_size)(text_input)    \n",
    "\n",
    "encoded_text = layers.LSTM(32)(embedded_text)  #Encodes the vectors in a single vector via an LSTM.\n",
    "\n",
    "question_input = Input(shape=(None,),     # Same process (with different layer instances) for the question.\n",
    "                              dtype='int32',\n",
    "                              name='question')\n",
    "\n",
    "embedded_question = layers.Embedding(32,  question_vocabulary_size)(question_input)\n",
    "\n",
    "encoded_question= layers.LSTM(16)(embedded_question)   \n",
    "\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question], axis = -1) #Concatenation\n",
    "\n",
    "answer = layers.Dense(answer_vocabulary_size, activation='softmax')(concatenated) # Adds a softmax classifier on top.\n",
    "\n",
    "model = Model([text_input, question_input], answer) # Specify the two inputs and outputs at model instantiation.\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "                         loss='categorical_crossentropy',\n",
    "                         metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 7.2  Feeding Data to a multi-input model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1000\n",
    "max_length = 100\n",
    "\n",
    "text = np.random.randint(1, text_vocabulary_size,\n",
    "                         size=(num_samples, max_length))      # Generates dummy Numpy data\n",
    "\n",
    "question = np.random.randint(1, question_vocabulary_size,\n",
    "                         size=(num_samples, max_length))\n",
    "\n",
    "answers = np.random.randint(0, 1, \n",
    "                         size=(num_samples, answer_vocabulary_size))  # Answers are 1hot encoded, not integers.\n",
    "\n",
    "model.fit([text, question], answers, epochs=10, batch_size=128)  # Fitting using a list of inputs.\n",
    "\n",
    "model.fit({'text': text, 'question': question}, answers,\n",
    "          epochs=10, batch_size=128)    # Fitting using a dictionary of inputs(only if inputs are named)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.3 Multi-output models: Functional API also builds models with multiple(outputs)(heads). e.g., a network attempting\n",
    "                           to simultaneously predict different props of the data such as social media posts predicting \n",
    "                           attributes of a person such as age, gender and income level.                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 7.3: Functional API implementation of a three output model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "vocabulary_size = 50000\n",
    "num_income_groups = 10\n",
    "\n",
    "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "embedded_posts = layers.Embedding(256, vocabulary_size)(posts_input)\n",
    "x = layers.Conv1D(128, 5, activation='relu')(embedded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "age_prediction = layers.Dense(1, name='age')(x)\n",
    "income_prediction = layers.Dense(num_income_groups, activation='softmax', name='income')(x)\n",
    "gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\n",
    "\n",
    "model = Model(posts_input, [age_prediction, income_prediction, gender_prediction])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 7.4: Compilation options of a multi-output model: multiple losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "                 loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'])\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'age': 'mse',\n",
    "                    'income': 'categorical_crossentropy',\n",
    "                    'gender': 'binary_crossentropy'}) # Equivalent possible only if you give names to the output layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 7.5: Compilation options of a multi-output model: loss weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "                 loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'],\n",
    "              loss_weights=[0.25, 1., 10.])\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'age': 'mse',\n",
    "                    'income': 'categorical_crossentropy',\n",
    "                    'gender': 'binary_crossentropy'}, # Equivalent possible only if you give names to the output layers\n",
    "              loss_weights={'age': 0.25,\n",
    "                            'income': 1.,\n",
    "                            'gender': 10.})      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing 7.6: Feeding data to a multi-output model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(posts, [age_targerts, income_targets, gender_targets],\n",
    "          epochs=10, batch_size=64)\n",
    "#age_targets, income_targets and gender_targets are assumed to be numpy arrays\n",
    "modelfit(posts, { 'age': age_targets,\n",
    "                  'income': income_targets,\n",
    "                  'gender': gender_targets},\n",
    "         epochs=10, batch_size=64)   # Equivalent(possible only if you give name to the output layers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
