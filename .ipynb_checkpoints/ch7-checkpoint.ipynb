{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Deep Learning Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1.1 Introduction to the functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, layers\n",
    "input_tensor = Input (shape=(32,))     # A tensor\n",
    "dense = layers.Dense(32, activation = 'relu')   # A layer is a function\n",
    "output_tensor = dense(input_tensor)         # A layer may be called a tensor and it returns a tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimal Eg., Sequential Model with its eq in functional API side by side:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "seq_model = Sequential()       # Seq Md\n",
    "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
    "seq_model.add(layers.Dense(32, activation='relu'))\n",
    "seq_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "input_tensor = Input(shape=(64,))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)    # Func eq\n",
    "\n",
    "model = Model(input_tensor, output_tensor)   # The Model class turns an input tensor and output tensor in2 a model\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The APi is same as that of sequntial when it comes to compiling training or evaluating such an instance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')  # Compiles the model\n",
    "\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000, 64))\n",
    "y_train = np.random.random((1000, 10))         # Gen dummy numpy data to train on\n",
    "\n",
    "model.fit(x_train, y_train,epochs=10, batch_size=128)     # Trains the model for 10 epochs\n",
    "score = model.evaluate(x_train, y_train)       # evaluates the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-input models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functional API helps build models having multiple inputs. Use Keras merge operation such as keras.layers.add, keras.layers.concatenate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Functional API implwemetation of a two-point question-answering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "text_input = Input(shape=(None,), dtype = 'int32', name = 'text')     #The text input is a variable-length sequence\n",
    "                                                                     #of integers. Note: U can optionally name the inputs.\n",
    "embedded_text = layers.Embedding(         # Embeds the inputs into a sequence of vectors of size 64.                \n",
    "    64, text_vocabulary_size)(text_input)    \n",
    "\n",
    "encoded_text = layers.LSTM(32)(embedded_text)  #Encodes the vectors in a single vector via an LSTM.\n",
    "\n",
    "question_input = Input(shape=(None,),     # Same process (with different layer instances) for the question.\n",
    "                              dtype='int32',\n",
    "                              name='question')\n",
    "\n",
    "embedded_question = layers.Embedding(32,  question_vocabulary_size)(question_input)\n",
    "\n",
    "encoded_question= layers.LSTM(16)(embedded_question)   \n",
    "\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question], axis = -1) #Concatenation\n",
    "\n",
    "answer = layers.Dense(answer_vocabulary_size, activation='softmax')(concatenated) # Adds a softmax classifier on top.\n",
    "\n",
    "model = Model([text_input, question_input], answer) # Specify the two inputs and outputs at model instantiation.\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "                         loss='categorical_crossentropy',\n",
    "                         metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 7.2  Feeding Data to a multi-input model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1000\n",
    "max_length = 100\n",
    "\n",
    "text = np.random.randint(1, text_vocabulary_size,\n",
    "                         size=(num_samples, max_length))      # Generates dummy Numpy data\n",
    "\n",
    "question = np.random.randint(1, question_vocabulary_size,\n",
    "                         size=(num_samples, max_length))\n",
    "\n",
    "answers = np.random.randint(0, 1, \n",
    "                         size=(num_samples, answer_vocabulary_size))  # Answers are 1hot encoded, not integers.\n",
    "\n",
    "model.fit([text, question], answers, epochs=10, batch_size=128)  # Fitting using a list of inputs.\n",
    "\n",
    "model.fit({'text': text, 'question': question}, answers,\n",
    "          epochs=10, batch_size=128)    # Fitting using a dictionary of inputs(only if inputs are named)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.3 Multi-output models: Functional API also builds models with multiple(outputs)(heads). e.g., a network attempting\n",
    "                           to simultaneously predict different props of the data such as social media posts predicting \n",
    "                           attributes of a person such as age, gender and income level.                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 7.3: Functional API implementation of a three output model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "vocabulary_size = 50000\n",
    "num_income_groups = 10\n",
    "\n",
    "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "embedded_posts = layers.Embedding(256, vocabulary_size)(posts_input)\n",
    "x = layers.Conv1D(128, 5, activation='relu')(embedded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "age_prediction = layers.Dense(1, name='age')(x)\n",
    "income_prediction = layers.Dense(num_income_groups, activation='softmax', name='income')(x)\n",
    "gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\n",
    "\n",
    "model = Model(posts_input, [age_prediction, income_prediction, gender_prediction])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 7.4: Compilation options of a multi-output model: multiple losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "                 loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'])\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'age': 'mse',\n",
    "                    'income': 'categorical_crossentropy',\n",
    "                    'gender': 'binary_crossentropy'}) # Equivalent possible only if you give names to the output layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 7.5: Compilation options of a multi-output model: loss weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "                 loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'],\n",
    "              loss_weights=[0.25, 1., 10.])\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'age': 'mse',\n",
    "                    'income': 'categorical_crossentropy',\n",
    "                    'gender': 'binary_crossentropy'}, # Equivalent possible only if you give names to the output layers\n",
    "              loss_weights={'age': 0.25,\n",
    "                            'income': 1.,\n",
    "                            'gender': 10.})      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing 7.6: Feeding data to a multi-output model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(posts, [age_targerts, income_targets, gender_targets],\n",
    "          epochs=10, batch_size=64)\n",
    "#age_targets, income_targets and gender_targets are assumed to be numpy arrays\n",
    "modelfit(posts, { 'age': age_targets,\n",
    "                  'income': income_targets,\n",
    "                  'gender': gender_targets},\n",
    "         epochs=10, batch_size=64)   # Equivalent(possible only if you give name to the output layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1.4: Directed acyclic graphs of layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural networks in Keras are also allowed to be arbitrary directed acyclic graphs of layers.\n",
    "# These graphs dont have cycles.\n",
    "# Its impossible for a tensor x to become the input of one of the layers that generated x\n",
    "# The only processing loops that are allowed(i.e., recurrent connections) are those internal to recurrent layers\n",
    "# Several common nn components are implemented as graph. Notable (1) Inception Modules, (2) Residual connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXAMPLE: MODEL IMPLEMENTATION OF INCEPTION MODULE EXAMPLE USING THE FUNCTIONAL API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "branch_a = layers.Conv2D(128, 1,\n",
    "                         activation='relu', strides=2)(x)\n",
    "#Above:Every branch has the same stride value (2),\n",
    "#which is necessary to keep all branch outputs\n",
    "#the same size so you can concatenate them\n",
    "branch_b = layers.Conv2D(128, 1,\n",
    "                         activation='relu')(x)\n",
    "branch_b = layers.Conv2D(128, 3,\n",
    "                         activation='relu', strides=2)(branch_b) # In this branch, striding occurs in the spatial convolution layer.\n",
    "branch_c = layers.AveragePooling2D(3, strides=2)(x)\n",
    "branch_c = layers.Conv2D(128, 3, activation='relu')(branch_c)  # In this branch, striding occurs in the average pooling layer.\n",
    "branch_d = layers.Conv2D(128, 1,\n",
    "                         activation='relu')(x)\n",
    "branch_a = layers.Conv2D(128, 3,\n",
    "                         activation='relu')(branch_d)\n",
    "output = layers.concatenate(\n",
    "    [branch_a, branch_b, branch_c, branch_d], axis=-1)  # Concatenates the branch outputs to obtain the module output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: The full Inception V3 architecture is available in Keras as keras.applications.inception_v3.InceptionV3, including weights pretrained on the ImageNet dataset. 'Xception', another model. literally stands for extreme inception, inspired by Inception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESIDUAL CONNECTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A residual connection consists of making the output of an earlier layer available as input to a later layer, effectivelycreating a shortcut in a sequential network. Example below assuming the existence of a 4D input tensor x:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "x = ...\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)  # Applies a transformation to x\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "\n",
    "y = layers.add([y, x])     # Adds the original x back to the output features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the following imp a residual connection when the feature-map sizes differ, using a linear residual connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "x = ...\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.MaxPooling2D(2, strides=2)(y)\n",
    "\n",
    "residual = layers.Conv2D(128, 1, strides=2, padding='same')(x)  # Uses a 1 x 1 convolution to linearly downsample the \n",
    "                                                                # original x tensor to the same shape as y.\n",
    "\n",
    "y = layers.add([y, residual])    # Adds the residual tensor back to the output features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representational bottlenecks in deep learning\n",
    "Residual connections, by reinjecting earlier information downstream, help to mitigate line losses. when in sequential\n",
    "models each successive representation layer is built on top of activated layer, with small layers, the models might\n",
    "be constrained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vanishing gradients\n",
    "Just like the LSTM layer in feedback recurrent networks introduces a carry tract that propagates information parallel to the\n",
    "main processing track, Residual connections in feedforward deep networks introduce a purely linear information carry\n",
    "track parallel to the main layer stack, this helping to propagate gradients through arbitrary deep stack of layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.5 Layer weight sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Imp Feature of Functional API: ability to reuse a layer instance several times, calling layer instance twice, same \n",
    "                               weights are used with every call and no new layer for each call is instantiated.\n",
    "                               Several branches share the same representations and learn these reps 4 diff input sets.\n",
    "                               e.g., 0 and 1 output score by model with inputs two sentences (assess semantic similarity btw)\n",
    "    \n",
    "    Instead of learning two independent models for processing each input sentence, both sentences shall be processed\n",
    "    with a single LSTM layer. The reps(weights) of this LSTM layer are learned based on both inputs simultaneously.\n",
    "    This is what is called a Siamese LSTM model or shared LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Siamese LSTM model implementation using layer sharing in the Keras functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "lstm = layers.LSTM(32)                        # Instantiates a single LSTM layer once\n",
    "\n",
    "left_input = Input(shape=(None, 128))  # Building left branch of the model: inputs are variable-length sequences of \n",
    "                                       # vectors of size 128 \n",
    "left_output = lstm(left_input)\n",
    "\n",
    "right_input = Input(shape=(None, 128))\n",
    "\n",
    "right_output = lstm(right_input) # Building right branch of the model: when you call an existing layer instance\n",
    "                                 # you reuse its weights\n",
    "\n",
    "merged = layers.concatenate([left_output, right_output], axis=-1)\n",
    "predictions = layers.Dense(1, activation='sigmoid')(merged)     # Builds the classifier on top\n",
    "\n",
    "model = Model([left_input, right_input], predictions)\n",
    "model.fit([left_data, right_data], targets)      # Instantiating and training the model: when you train such a model\n",
    "#,the weights of the LSTM layer are updated based on both inputs.\n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1.6: Models as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(x)    # Call a model on an input tensor and retrieve an output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1, y2 = model[x1, x2]  # When there are multiple input and output tensors, a list of tensors should be called"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights of the model are reused when the model instance is called exactly like layer instance.\n",
    "# e.g., a vision model using dual camera as its input; two parallel cameras, a few centimeters(1 inch apart).\n",
    "# Such a model can percieve depth useful in many apps. No need for two indepndent models to extract visual \n",
    "# features for the left and right b4 merging the two feeds. Such lowlevel processing can be shared across the\n",
    "# two inputs:i.e, done via layers using the same wights and thus representations. \n",
    "\n",
    "# Imp Siamese vision model(shared convolution base in keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import applications\n",
    "from keras import Input\n",
    "\n",
    "xception_base = application.Xception(weights = None, \n",
    "                                      include_top=False)  # The base image-processing model is the Xception network\n",
    "                                                                        #(convolutional base only)\n",
    "left_input = Input(shape=(250, 250, 3))\n",
    "right_input = Input(shape=(250, 250, 3))   # The inputs are 250 x 250 RGB images\n",
    "\n",
    "left_features = xception_base(left_input)\n",
    "right_input = xception_base(right_input)      # Calls the same vision model twice\n",
    "\n",
    "merged features = layers.concatenate(\n",
    "        [left_features, right_input], axis=-1)  # The merged features contain information from the right visual feed\n",
    "                                                # and the left visual feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2.1: Using Callbacks to act on a model during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop training when the validation loss is no longer improving.  Achievable through a keras callback.\n",
    "A callback is an object( a class inst imp specific meth) that is passed to the model in the call to fit and that\n",
    "is called by the model at various points during training.\n",
    "Examples of ways of using callbacks\n",
    "\n",
    "Model checkpointing- Saving the current weights of the model at different points during training.\n",
    "\n",
    "Early stopping- Interrupting training when the validation loss is no longer improving(optimization).\n",
    "\n",
    "Dynamically adjusting the value of certain params during trining-such as the learning rate of the optimizer\n",
    "\n",
    "Logging training and validation metrics during training or visualizing the reps learned by the model as dey r updated.\n",
    "\n",
    "The Keras progress bar is a callback\n",
    "\n",
    "The keras.callback includes a no. of built-in callbacks:-\n",
    "    \n",
    "    keras.callbacks.ModelCheckpoint\n",
    "    keras.callbacks.EarlyStopping\n",
    "    keras.callbacks.LearningRateScheduler\n",
    "    keras.callbacks.ReduceLROnPlateau\n",
    "    keras.callbacks.CSVLogger\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THE MODEL CHECKPOINT AND EARLYSTOPPING CALLBACKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to interrupt training as soon as overfitting starts to avoid training model for a smaller no. of epochs\n",
    "EarlyStopping callback typucally used in combo with ModelCheckpoint, continually saving the model during the training\n",
    "and hence optionally save the best model so far; the version of model achieving the best per on end of an epoch):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "callbacks_list = [ # Callbacks passed 2 model via callbacks args in fit, taking a list of call backs:any\n",
    "    keras.callbacks.EarlyStopping(    # Interrupts training when improvement stops\n",
    "        monitor = 'acc',              # Monitors the model's validation accuracy\n",
    "        patience=1,                   # Interrupts training when accuracy has stopped improving for more than one epoch i.e, 2epochs\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(  # Saves the current weights after every epoch\n",
    "        filepath='my_model.h5',       # Path to the destination model file\n",
    "        monitor='val_loss',     # These 2 args (one below) means model file wont be overwritten unless val_loss  \n",
    "        save_best_only=True,    # has improved, allowing to keep the best model during training        \n",
    "    )\n",
    "]\n",
    "\n",
    "model.compile(optimizer='rmsprop',         # Monitor accuracy to be part of the model's metrics. \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.fit(x, y,                                 # Note: Since callback monitors validation loss and validation\n",
    "          epochs=10,                            #       accuracy, validation_data needs to be passed to call to fit.     \n",
    "          batch_size=32,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THE REDUCELRONPLATEAU CALLBACK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce learning rate when validation loss stops improving. \n",
    "Reducing or increasing the learning rate in case of a loss plateau is an effective strategy to get out of local\n",
    "minima during training. Example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list - [\n",
    "    keras.callbacks.ReduceLROnPlateau(   \n",
    "        monitor='val_loss'             # monitors the model's validation loss\n",
    "        factor=0.1,                    # Divides the learning rate by 10 when trigerred\n",
    "        patience=10,                   # Callback trig after val_loss stops improving for 1-0 epochs\n",
    "    )\n",
    "]\n",
    "\n",
    "model.fit(x, y,                                 # Note: Since callback monitors validation loss and validation\n",
    "          epochs=10,                            #       accuracy, validation_data needs to be passed to call to fit.     \n",
    "          batch_size=32,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(x_val, y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
